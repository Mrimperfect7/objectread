<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Voice Object Detector</title>
  <style>
    body {
      background-color: #111;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      padding: 20px;
    }
    video {
      width: 100%;
      max-width: 600px;
      margin-top: 10px;
      border-radius: 12px;
    }
    #start-btn {
      padding: 14px 28px;
      font-size: 18px;
      background-color: #00aa88;
      color: white;
      border: none;
      border-radius: 8px;
      margin-top: 30px;
      cursor: pointer;
    }
    #status {
      font-size: 18px;
      margin-top: 12px;
    }
  </style>
</head>
<body>
  <h2>ðŸ§  Object Detector with Voice (utter)</h2>
  <button id="start-btn">Start Detection</button>
  <video id="video" autoplay muted playsinline hidden></video>
  <p id="status">Click the button to begin</p>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script>
    let model;
    let lastSpoken = '';
    let isSpeaking = false;
    const synth = window.speechSynthesis;

    const startBtn = document.getElementById("start-btn");
    const video = document.getElementById("video");
    const statusText = document.getElementById("status");

    startBtn.onclick = async () => {
      startBtn.style.display = 'none';
      statusText.innerText = "Loading model...";
      model = await cocoSsd.load();
      statusText.innerText = "Model loaded. Starting camera...";

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: { exact: "environment" } }
      });

      video.srcObject = stream;
      video.hidden = false;

      video.onloadeddata = () => {
        statusText.innerText = "Detecting...";
        detectFrame();
      };
    };

    async function detectFrame() {
      const predictions = await model.detect(video);

      if (predictions.length > 0) {
        const label = predictions[0].class;
        statusText.innerText = "Detected: " + label;

        if (label !== lastSpoken && !isSpeaking) {
          lastSpoken = label;
          speakWithUtter(label);
        }
      } else {
        statusText.innerText = "No object detected";
      }

      requestAnimationFrame(detectFrame);
    }

    function speakWithUtter(text) {
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.pitch = 1;
      utter.rate = 1;

      utter.onstart = () => {
        isSpeaking = true;
        console.log("Speaking:", text);
      };

      utter.onend = () => {
        isSpeaking = false;
        console.log("Done speaking:", text);
      };

      synth.cancel(); // Stop previous speech
      synth.speak(utter);
    }
  </script>
</body>
</html>
