<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Object Detection with Voice</title>
  <style>
    body {
      background-color: #111;
      color: white;
      font-family: sans-serif;
      text-align: center;
      margin: 0;
      padding: 20px;
    }
    video {
      width: 100%;
      max-width: 600px;
      margin-top: 10px;
      border-radius: 12px;
    }
    #start-btn {
      padding: 12px 24px;
      font-size: 18px;
      background: #00aa88;
      color: white;
      border: none;
      border-radius: 8px;
      margin-top: 40px;
      cursor: pointer;
    }
    #status {
      font-size: 20px;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <h2>ðŸ§  Object Detector with Voice</h2>
  <button id="start-btn">Start Detection</button>
  <video id="video" autoplay muted playsinline hidden></video>
  <p id="status">Click the button to start.</p>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script>
    let model, lastSpoken = '', speaking = false;
    let selectedVoice = null;

    const btn = document.getElementById("start-btn");
    const video = document.getElementById("video");
    const statusText = document.getElementById("status");
    const synth = window.speechSynthesis;

    // Wait for voices to be loaded
    function loadVoices() {
      return new Promise(resolve => {
        let voices = synth.getVoices();
        if (voices.length !== 0) {
          resolve(voices);
        } else {
          synth.onvoiceschanged = () => {
            voices = synth.getVoices();
            resolve(voices);
          };
        }
      });
    }

    async function initSpeech() {
      const voices = await loadVoices();
      selectedVoice = voices.find(v => v.lang.startsWith('en')) || voices[0];
      console.log("Voice loaded:", selectedVoice.name);
    }

    btn.onclick = async () => {
      btn.disabled = true;
      await initSpeech();
      statusText.textContent = "Loading model...";
      model = await cocoSsd.load();
      statusText.textContent = "Model loaded. Starting camera...";

      // Get back camera if possible
      const constraints = {
        video: {
          facingMode: { exact: "environment" }
        }
      };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        video.hidden = false;

        video.onloadeddata = () => {
          statusText.textContent = "Detecting objects...";
          detectFrame();
        };
      } catch (err) {
        alert("Failed to access camera: " + err.message);
      }
    };

    async function detectFrame() {
      const predictions = await model.detect(video);

      if (predictions.length > 0) {
        const label = predictions[0].class;
        statusText.textContent = `Detected: ${label}`;

        if (label !== lastSpoken && !speaking) {
          lastSpoken = label;
          speak(label);
        }
      } else {
        statusText.textContent = "No object detected";
      }

      requestAnimationFrame(detectFrame);
    }

    function speak(text) {
      if (synth.speaking) {
        console.warn("Still speaking. Skipping.");
        return;
      }

      speaking = true;

      const utter = new SpeechSynthesisUtterance(text);
      utter.voice = selectedVoice;
      utter.lang = selectedVoice.lang || "en-US";
      utter.pitch = 1;
      utter.rate = 1;

      utter.onend = () => {
        speaking = false;
      };

      console.log("Speaking:", text);
      synth.speak(utter);
    }
  </script>
</body>
</html>
